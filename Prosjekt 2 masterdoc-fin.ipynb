{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prosjekt 2: Introduksjon til maskinlæring\n",
    "## Frederick Nilsen, Mia Rødde, Sara Abnar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialisering og generell algoritme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## IMPORTS\n",
    "\n",
    "import numpy as np #Numpy-biblioteket\n",
    "import matplotlib.pyplot as plt #Generell plotting\n",
    "from loader import * #Utdelt kode for innlastning av MNIST-data\n",
    "from plotting import * #Plottingfunksjoner fra utdelt kode\n",
    "from spirals import get_data_spiral_2d #Spiralgenererende funksjon fra utdelt kode\n",
    "import pickle # Lar oss lagre en binær dump av vekter fra trening"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## GLOBAL CONSTS AND DEFINITIONS\n",
    "\n",
    "sigma = lambda x : np.tanh(x)         # Activation function\n",
    "eta = lambda x : 0.5*(1+np.tanh(x/2)) # Scalar function     \n",
    "eta_ddx = lambda x :  0.25*(1-np.tanh(x/2)*np.tanh(x/2)) # Derivative of eta\n",
    "sigma_ddx = lambda x: 1-(np.tanh(x))**2 # Derivative of sigma\n",
    "\n",
    "##### Global consts for the first dataset\n",
    "K = 10 # Antall lag\n",
    "d = 2 # Antall dimensjoner\n",
    "tau = 0.1 # Læringsparameter, brukes i \"plain vanilla\"-algoritmen, [0.01,0.1]\n",
    "np.random.seed(0) #Definerer vårt seed, gjør det enklere å debugge\n",
    "Y0, C = get_data_spiral_2d(200) #Default n=200\n",
    "I = Y0.shape[1]\n",
    "\n",
    "np.random.seed(0)\n",
    "W = np.random.randn(K,d,d)\n",
    "np.random.seed(0)\n",
    "b = np.random.randn(K,d,1)     #W,b,mu og w initieres med tilfeldige verdier \n",
    "np.random.seed(0)\n",
    "mu = np.random.randn()\n",
    "np.random.seed(0)\n",
    "w = np.random.randn(d,1)\n",
    "h = 0.1 # Steglengde\n",
    "\n",
    "Ulst = [W, b, w, mu] # Python-liste bestående av vektobjektene, brukes bl.a Adam-metoden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Funksjoner\n",
    "\n",
    "'''\n",
    "saveU dumper binærdata av vektene (Ulst), til tekstfil.\n",
    "Dette muliggjør å opphente vektene for testing av presisjon uten å måtte trene algoritmen på nytt\n",
    "loadU laster inn Ulst fra en innlastet fil. Antatt at fil eksisterer og ikke kaster exception\n",
    "'''\n",
    "def saveU(dataset=\"spirals\"):\n",
    "    with open('weights-' + dataset + '.txt', 'wb') as f:\n",
    "        pickle.dump(Ulst,f)\n",
    "\n",
    "def loadU(dataset=\"spirals\"):\n",
    "    with open('weights' + dataset + '.txt','r') as f:\n",
    "        pickle.load(f)\n",
    "'''\n",
    "Labels, C, er en array av bools. Her har vi antatt at true er rød og false er blå,\n",
    "og tilordnet fargene som brukes til plotting. Bruker list comprehension\n",
    "'''\n",
    "def getColorFromLabel(C):\n",
    "    colorLst = []\n",
    "    colorLst.append('r' if value else 'b' for value in C)\n",
    "    return colorLst\n",
    "C_colors = getColorFromLabel(C) #Fargeliste til plotting for første datasett\n",
    "\n",
    "\n",
    "'''\n",
    "YK(W,b,Ystart=Y0)\n",
    "Tar inn vektene W og b eventuelt en egendefinert startverdi for Y. Som standard brukes Y0 fra spiraloppgaven,\n",
    "men dersom spesifisert fungerer den tilsvarende for MNIST-oppgaven.\n",
    "Funksjonen tilsvarer likning (1) i oppgavetekst.\n",
    "'''\n",
    "def YK(W, b, Ystart=Y0):\n",
    "    #tom Y-matrise, 3-dimensjonalt numpy-array\n",
    "    Ym = np.zeros((K+1,d,I))\n",
    "    Ym[0,:,:] = np.copy(Ystart)\n",
    "    k=0\n",
    "    while k < K:\n",
    "        Ym[k+1] = Ym[k] + h*sigma(W[k]@Ym[k] + b[k])\n",
    "        k+=1\n",
    "    return Ym\n",
    "\n",
    "'''\n",
    "getGradients\n",
    "Tar inn lag K, samt vektene, C og Y og regner ut alle gradienter som beskrevet i prosjektbeskrivelsen og returnerer dem.\n",
    "Store deler av koden er en implementasjon av henholdsvis likning (5), (6), (7), (8) og (9)\n",
    "Også getGradients tar utgangspunkt i data fra spiraloppgave med mindre annet er spesifisert.\n",
    "Alle arrays deklareres med np.zeros(), og fylles deretter opp som beskrevet i oppgaveteksten.\n",
    "'''\n",
    "def getGradients(K, W, b, w, mu, c=C):\n",
    "    lastY = YK_list[-1,:,:]\n",
    "    P = np.zeros((Y_all.shape)) #Initalisering\n",
    "    P[K,:,:] = w@np.transpose((Zf(w,mu, lastY)-c)*eta_ddx(np.transpose(lastY)@w+mu))  #(7)\n",
    "    \n",
    "    dJdMU = eta_ddx(np.transpose(np.transpose(lastY)@w+mu))@(Zf(w,mu, lastY)-c) #(5)\n",
    "    dJdw = lastY@((Zf(w,mu, lastY)-c)*eta_ddx(np.transpose(lastY)@w+mu))  #(6)\n",
    "    for k in range(K,0,-1):\n",
    "        P[k-1,:,:] = P[k,:,:]+h*np.transpose(W[k-1,:,:])@(sigma_ddx(W[k-1,:,:]@Y_all[k-1,:,:]+b[k-1,:,:])*P[k,:,:])  #(8) \n",
    "    dJdWk = np.zeros((K,d,d)) #Init\n",
    "    dJdBk = np.zeros((K,d,1)) #Init\n",
    "    \n",
    "    for k in range(0,K):\n",
    "        dJdWk[k] = h*(P[k+1]*sigma_ddx(W[k,:,:]@Y_all[k,:,:]+b[k,:,:]))@np.transpose(Y_all[k,:,:])  #(9)\n",
    "        dJdBk[k] = h*(P[k+1]*sigma_ddx(W[k,:,:]@Y_all[k,:,:]+b[k,:,:]))@np.ones((I,1)) #(10)\n",
    "    return dJdWk, dJdBk, dJdw, dJdMU\n",
    "\n",
    "\n",
    "'''\n",
    "AdamAlg\n",
    "Tar inn liste av vekter (Ulst), Y0 og C fra importert data samt m og v.\n",
    "Variablene m og v bestemmes av AdamAlg, og er en liste med samme lengde som Ulst.\n",
    "Counter er en global variabel som følger med på antall iterasjoner og brukes i potensuttrykket til mhat og vhat.\n",
    "\n",
    "gradLst består av en liste av gradientobjektene fra getGradients(), og vi kjører deretter en for-løkke\n",
    "for å oppdatere vektene for alle gradienter.\n",
    "Funksjonen returnerer Ulst, en liste over oppdaterte vekter.\n",
    "Funksjonen returnerer også m og v da neste kall på funksjonen avhenger av m- og v-verdiene fra forrige beregning.\n",
    "'''\n",
    "def AdamAlg(Ulst, m, v, c=C, Ystart=Y0):\n",
    "    beta1 = 0.9\n",
    "    beta2 = 0.999\n",
    "    alpha = 0.01\n",
    "    epsilon = 1e-8\n",
    "    W, b, w, mu = Ulst\n",
    "    gradLst = [x for x in getGradients(K, W, b, w, mu, c)] #Syntaks tvinger data til liste og ikke tuple\n",
    "    for i in range(len(gradLst)):\n",
    "        g = gradLst[i]\n",
    "        m[i] = beta1*m[i]+(1-beta1)*g\n",
    "        v[i] = beta2*v[i]+(1-beta2)*(g*g)\n",
    "        mhat = m[i]/(1-beta1**(counter))\n",
    "        vhat = v[i]/(1-beta2**(counter))\n",
    "        Ulst[i] -= alpha*mhat/(np.sqrt(vhat)+epsilon)\n",
    "    return Ulst, m, v"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testproblem 1 - punkter i planet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "YK_list = YK(W,b) \n",
    "lastY = YK_list[-1,:,:]\n",
    "\n",
    "Zf = lambda w,mu,finalY=lastY : eta(np.transpose(finalY)@w +mu) #(2)\n",
    "Z=Zf(w,mu) #Flytt til mer oversiktlig plass\n",
    "Jf = lambda Z=Zf(w,mu), ce=C : 1/2*np.linalg.norm(Z-ce)**2 #(3) Kostnadsfunksjon\n",
    "J = Jf() #Flytt til mer oversiktlig plass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hovedalgoritmecelle\n",
    "converged = False #Slett\n",
    "counter = 1 \n",
    "\n",
    "#initializing list\n",
    "m = [0 for x in range(len(Ulst))]\n",
    "v = [0 for x in range(len(Ulst))]\n",
    "\n",
    "#for AdamAlg\n",
    "for i in range(1,10001): #\"while not converged\" gjort om til for med angitt antall iterasjoner\n",
    "    Ulst, m, v = AdamAlg(Ulst, m, v)\n",
    "    counter +=1 \n",
    "\n",
    "W, b, w, mu = Ulst\n",
    "saveU()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#Plain Vanilla, brukte denne for å teste oppgave 1\n",
    "\n",
    "for i in range(1,5000):   #Skal være 40001\n",
    "    #print(YK_list)\n",
    "    dJdWk, dJdBk, dJdw, dJdMU = getGradients(K, W, b, w, mu)\n",
    "    W-=tau*dJdWk\n",
    "    b-=tau*dJdBk\n",
    "    w-=tau*dJdw\n",
    "    mu-=tau*dJdMU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Test-celle for spiraldata\n",
    "Denne cellen genererer et nytt sett med data for testing, og bruker vektene fra treningen til å beregne Z/Y\n",
    "Deretter plottes punktene for hvert lag.\n",
    "'''\n",
    "testY, testC = get_data_spiral_2d(200) #Er det en idé å lage testing som funksjoner og ikke bare kode i en celle?\n",
    "#Ulst = loadU()\n",
    "#W,b,w,mu = Ulst #Fjern kommentar bak hvis du er enig i å gjøre det sånn\n",
    "trainedY = YK(W, b, testY)\n",
    "lastY = trainedY[-1,:,:]\n",
    "print(Jf(Zf(w,mu, lastY), testC)) #Skal vi printe dette?\n",
    "\n",
    "#forward function\n",
    "def classifications(K, W, b, w, mu): #Funket dette? Hvis ikke må vi base slette\n",
    "    def classifying_unknown_points(Y0):\n",
    "        Y = YK_list[-1,:,:]\n",
    "        Z = Zf(w, mu, Y)\n",
    "        return Z\n",
    "    return classifying_unknown_points\n",
    "f = classifications(K, W, b, w, mu)\n",
    " \n",
    "#Last function\n",
    "def classifications2(w, mu): #Funket dette? Hvis ikke må vi base slette\n",
    "    def classifying_unknown_points2(Y0):\n",
    "        Z = Zf(w, mu, lastY)\n",
    "        return Z\n",
    "    return classifying_unknown_points2\n",
    "g = classifications2(w, mu)\n",
    "\n",
    "plot_progression(trainedY, testC)\n",
    "#plot_model(f, lastY, testC, I) #Funket dette? Hvis ikke må vi base slette\n",
    "#plot_separation(g, lastY, testC, I) #Funket dette? Hvis ikke må vi base slette"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lowerBoundary_setTrueZ = [0.65, 0.75, 0.85, 0.95, 0.99]\n",
    "'''\n",
    "checkResults\n",
    "Tilleggsfunksjon for å systematisere resultatene fra første datsett (spirals)\n",
    "Beregner Z og J med opptrente vekter og presenterer resultater.\n",
    "Ser deretter, basert på ulike presisjonsterskeler (lowerBoundary_setTrueZ) om algoritmen har tilordnet rikitg label opp mot C\n",
    "Linje 19 og 23 bruker list comprehension, men er tilsvarende en \"countif\"-funksjon,\n",
    "Teller altså antall True og tall rundt 1, som i spirals vil tilsvare blå farge, og i MNIST er tallet 7/andre digit\n",
    "^^^^^^ KANSKJE IKKE RIKTIG LINJENUMMER HVIS VI SLETTER TING\n",
    "'''\n",
    "def checkResults(n=I):\n",
    "    testY, testC = get_data_spiral_2d(n)\n",
    "    trainedY = YK(W, b, testY)\n",
    "    lastY = trainedY[K,:,:]\n",
    "    trainedZ = Zf(w,mu,lastY)\n",
    "\n",
    "    J_new=Jf(trainedZ,testC)\n",
    "    numTrue=0 #Slett\n",
    "    numJTrue = 0 #Slett\n",
    "    print(\"J_new:\", J_new)\n",
    "    numTrue = sum(1 if testC[i][0] else 0 for i in range(n))\n",
    "    print(\"Antall true:\", numTrue)\n",
    "    print(\"Lower boundary \\t Antall true i følge J \\t\\t Success rate[%]\")\n",
    "    for lowerBound in lowerBoundary_setTrueZ:\n",
    "        numTrue_J = sum(1 if trainedZ[i][0] >=lowerBound else 0 for i in range(n))\n",
    "        success_rate = round(numTrue_J/numTrue*100, 5)\n",
    "        print(lowerBound, numTrue_J, success_rate, sep=\"\\t\\t\\t\")\n",
    "    \n",
    "\n",
    "lastY = trainedY[K,:,:]\n",
    "trainedZ = Zf(w,mu,lastY) #Hva bruker vi disse to til?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkResults() #Ser rart ut å ha på egen celle?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testproblem 2 - Siffergjenkjenning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#INITIALISING LIST, PART 2\n",
    "K = 10\n",
    "Y0pic, C_pic = get_dataset(\"testing\")\n",
    "d = Y0pic.shape[0]\n",
    "I = Y0pic.shape[1]\n",
    "\n",
    "np.random.seed(0)\n",
    "W = np.random.randn(K,d,d)\n",
    "np.random.seed(0)\n",
    "b = np.random.randn(K,d,1)     #Reinitialiserer vektene til tilfeldige verdier\n",
    "np.random.seed(0) #Brannfakkel: kanskje ha en resetWeights()-funksjon?\n",
    "mu = np.random.randn()\n",
    "np.random.seed(0)\n",
    "w = np.random.randn(d,1)\n",
    "h = 0.1\n",
    "\n",
    "Ulst = [W, b, w, mu]\n",
    "YK_list = YK(W, b, Y0pic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Treningscelle for testsett 2'''\n",
    "counter = 1\n",
    "\n",
    "#initializing list\n",
    "m = [0 for x in range(len(Ulst))]\n",
    "v = [0 for x in range(len(Ulst))]\n",
    "\n",
    "#AdamAlg\n",
    "for i in range(1,101): #\"while not converged\" gjort om til for med angitt antall iterasjoner\n",
    "    Ulst, m, v = AdamAlg(Ulst, m, v, C_pic)\n",
    "    print(counter)\n",
    "    counter +=1 #Brukes i AdamAlg\n",
    "\n",
    "saveU(\"MNIST\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Test-celle for MNIST'''\n",
    "#Ulst = loadU(\"MNIST\")\n",
    "#W,b,w,mu = Ulst #Fjern kommentar bak hvis du er enig i å gjøre det sånn\n",
    "W, b, w, mu = Ulst #linje 2-3 vil evt erstatte dette da\n",
    "testpic, testCp = get_dataset(\"testing\")\n",
    "I = testpic.shape[1]\n",
    "d = testpic.shape[0]\n",
    "YK_list = YK(W, b, testpic)\n",
    "lastYPic = YK_list[K,:,:]\n",
    "\n",
    "trainedZ = Zf(w, mu, lastYPic)\n",
    "\n",
    "#koden går mye raskere men J er jo alt for høy: 117.54204154098629 #SLETT FØR VI LEVERER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lowerBoundary_setTrueZ = [0.65, 0.75, 0.85, 0.95, 0.99, 1.00] #Ulik forrige liste, bør vi holde oss til bare en?\n",
    "'''\n",
    "checkResultsPic fungerer på samme måte som checkResults\n",
    "'''\n",
    "def checkResultsPic(n=I): #Kanskje prøve å bruke gammel checkResults i stedet for ny funksjon?\n",
    "    J_new=Jf(trainedZ,testCp)\n",
    "    numTrue_J = np.array([]) \n",
    "    print(\"J_new:\", J_new)\n",
    "    numTrue = sum(1 if testCp[i][0] else 0 for i in range(n))\n",
    "    print(\"Antall true:\", numTrue)\n",
    "    print(\"Lower boundary \\t Antall true i følge J \\t\\t Success rate[%]\")\n",
    "    for lowerBound in lowerBoundary_setTrueZ:\n",
    "        numTrue_J = sum(1 if trainedZ[i][0] >=lowerBound else 0 for i in range(n))\n",
    "        success_rate = round(numTrue_J/numTrue*100, 5)\n",
    "        print(lowerBound, numTrue_J, success_rate, sep=\"\\t\\t\\t\")\n",
    "\n",
    "checkResultsPic()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
