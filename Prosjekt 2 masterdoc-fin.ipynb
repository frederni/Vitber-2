{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project 2:\n",
    "## Authors: Frederick Nilsen, Mia Rødde, Sara Abnar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Warnings\n",
    "\n",
    "* Ikke endre uten at de andre vet det\n",
    "* **Alltid** gå på Kernel -> Restart & Clear Output\n",
    "* Ikke skriv utenfor cellene og sånn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementation of set 1 - points in 2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## IMPORTS\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from loader import *\n",
    "from plotting import *\n",
    "from spirals import get_data_spiral_2d\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## GLOBAL CONSTS AND DEFINITIONS\n",
    "\n",
    "sigma = lambda x : np.tanh(x)         # Activation function\n",
    "eta = lambda x : 0.5*(1+np.tanh(x/2)) # Scalar function     \n",
    "eta_ddx = lambda x :  0.25*(1-np.tanh(x/2)*np.tanh(x/2)) # Derivative of eta\n",
    "sigma_ddx = lambda x: 1-(np.tanh(x))**2 # Derivative of sigma\n",
    "\n",
    "\n",
    "K = 10 # +1 gives number of layers, arbitrary number\n",
    "d = 2 # Ehh\n",
    "tau = 0.1 # learning parameter [0.01,0.1]\n",
    "np.random.seed(0)\n",
    "Y0, C = get_data_spiral_2d(200) #Default n=200\n",
    "I = Y0.shape[1]\n",
    "\n",
    "np.random.seed(0)\n",
    "W = np.random.randn(K,d,d)\n",
    "np.random.seed(0)\n",
    "b = np.random.randn(K,d,1)     #startverdier\n",
    "np.random.seed(0)\n",
    "mu = np.random.randn()\n",
    "np.random.seed(0)\n",
    "w = np.random.randn(d,1)\n",
    "h = 0.1\n",
    "\n",
    "Ulst = [W, b, w, mu]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## INITIALISATION CELL\n",
    "def saveU(dataset=\"spirals\"):\n",
    "    with open('weights-' + dataset + '.txt', 'wb') as f:\n",
    "        pickle.dump(Ulst,f)\n",
    "\n",
    "def loadU(dataset=\"spirals\"):\n",
    "    with open('weights' + dataset + '.txt','r') as f:\n",
    "        pickle.load(f)\n",
    "\n",
    "def getColorFromLabel(C):\n",
    "    colorLst = []\n",
    "    colorLst.append('r' if value else 'b' for value in C)\n",
    "    return colorLst\n",
    "C_colors = getColorFromLabel(C)\n",
    "\n",
    "\n",
    "#optimert funksjon\n",
    "def YK(W, b, Ystart=Y0):\n",
    "    #tom Y-matrise, 3-dimensjonalt numpy-array\n",
    "    Ym = np.zeros((K+1,d,I))\n",
    "    Ym[0,:,:] = np.copy(Ystart)\n",
    "    k=0\n",
    "    while k < K:\n",
    "        Ym[k+1] = Ym[k] + h*sigma(W[k]@Ym[k] + b[k])\n",
    "        k+=1\n",
    "    return Ym\n",
    "\n",
    "#Finner P_K\n",
    "def getGradients(K, W, b, w, mu, c=C, Ystart=Y0):\n",
    "    Y_all = YK(W,b, Ystart)\n",
    "    lastY = Y_all[-1,:,:]\n",
    "    P = np.zeros((Y_all.shape)) # init matrix\n",
    "    P[K,:,:] = w@np.transpose((Zf(w,mu, lastY)-c)*eta_ddx(np.transpose(lastY)@w+mu))  #(7)\n",
    "    \n",
    "    dJdMU = eta_ddx(np.transpose(np.transpose(lastY)@w+mu))@(Zf(w,mu, lastY)-c)   #(5), kunne også brukt '.T' for transpose\n",
    "    dJdw = lastY@((Zf(w,mu, lastY)-c)*eta_ddx(np.transpose(lastY)@w+mu))              #(6)\n",
    "    for k in range(K,0,-1):\n",
    "        P[k-1,:,:] = P[k,:,:]+h*np.transpose(W[k-1,:,:])@(sigma_ddx(W[k-1,:,:]@Y_all[k-1,:,:]+b[k-1,:,:])*P[k,:,:])  #(8) \n",
    "    dJdWk = np.zeros((K,d,d))\n",
    "    dJdBk = np.zeros((K,d,1))\n",
    "    \n",
    "    for k in range(0,K):\n",
    "        dJdWk[k] = h*(P[k+1]*sigma_ddx(W[k,:,:]@Y_all[k,:,:]+b[k,:,:]))@np.transpose(Y_all[k,:,:])  #(9)\n",
    "        dJdBk[k] = h*(P[k+1]*sigma_ddx(W[k,:,:]@Y_all[k,:,:]+b[k,:,:]))@np.ones((I,1)) #One not needed?#(10)\n",
    "    return dJdWk, dJdBk, dJdw, dJdMU\n",
    "\n",
    "\n",
    "#Adam descent algorithm\n",
    "def AdamAlg(Ulst, m, v, c=C, Ystart=Y0):\n",
    "    beta1 = 0.9\n",
    "    beta2 = 0.999\n",
    "    alpha = 0.01\n",
    "    epsilon = 1e-8\n",
    "    W, b, w, mu = Ulst\n",
    "    gradLst = [x for x in getGradients(K, W, b, w, mu, c, Ystart)]\n",
    "    for i in range(len(gradLst)):\n",
    "        g = gradLst[i]\n",
    "        m[i] = beta1*m[i]+(1-beta1)*g\n",
    "        v[i] = beta2*v[i]+(1-beta2)*(g*g)\n",
    "        mhat = m[i]/(1-beta1**(counter))\n",
    "        vhat = v[i]/(1-beta2**(counter))\n",
    "        Ulst[i] -= alpha*mhat/(np.sqrt(vhat)+epsilon)\n",
    "    return Ulst, m, v"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#GAMMEL ADAM\n",
    "def AdamAlg(uParam, U_ind, lastM, lastV, c=C, Ystart=Y0):\n",
    "    beta1 = 0.9\n",
    "    beta2 = 0.999\n",
    "    alpha = 0.01\n",
    "    epsilon = 1e-8\n",
    "    g = getGradients(K, W, b, w, mu, c, Ystart)[U_ind]\n",
    "    m = beta1*lastM+(1-beta1)*g\n",
    "    v = beta2*lastV+(1-beta2)*(g*g)\n",
    "    mhat = m/(1-beta1**(counter))\n",
    "    vhat = v/(1-beta2**(counter))\n",
    "    uParam -= alpha*mhat/(np.sqrt(vhat)+epsilon)\n",
    "    lastM = m\n",
    "    lastV = v\n",
    "    return uParam, lastM, lastV\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lager siste Y_k = Y_K\n",
    "YK_list = YK(W,b)\n",
    "lastY = YK_list[-1,:,:]\n",
    "\n",
    "Zf = lambda w,mu,finalY=lastY : eta(np.transpose(finalY)@w +mu)\n",
    "Z=Zf(w,mu)\n",
    "Jf = lambda Z=Zf(w,mu), ce=C : 1/2*np.linalg.norm(Z-ce)**2 #Cost function\n",
    "J = Jf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Algorithm\n",
    "converged = False\n",
    "counter = 1\n",
    "\n",
    "#initializing list\n",
    "m = [0 for x in range(len(Ulst))]\n",
    "v = [0 for x in range(len(Ulst))]\n",
    "\n",
    "#for AdamAlg\n",
    "for i in range(1,10001):   #Skal være 40001\n",
    "    Ulst, m, v = AdamAlg(Ulst, m, v)\n",
    "    counter +=1 \n",
    "\n",
    "W, b, w, mu = Ulst\n",
    "saveU()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#Plain Vanilla\n",
    "\n",
    "for i in range(1,5000):   #Skal være 40001\n",
    "    #print(YK_list)\n",
    "    dJdWk, dJdBk, dJdw, dJdMU = getGradients(K, W, b, w, mu)\n",
    "    W-=tau*dJdWk\n",
    "    b-=tau*dJdBk\n",
    "    w-=tau*dJdw\n",
    "    mu-=tau*dJdMU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testY, testC = get_data_spiral_2d(200)\n",
    "trainedY = YK(W, b, testY)\n",
    "lastY = trainedY[-1,:,:]\n",
    "print(Jf(Zf(w,mu, lastY), testC))\n",
    "\n",
    "#forward function\n",
    "def classifications(K, W, b, w, mu):\n",
    "    def classifying_unknown_points(Y0):\n",
    "        Y = YK_list[-1,:,:]\n",
    "        Z = Zf(w, mu, Y)\n",
    "        return Z\n",
    "    return classifying_unknown_points\n",
    "f = classifications(K, W, b, w, mu)\n",
    " \n",
    "#Last function\n",
    "def classifications2(w, mu):\n",
    "    def classifying_unknown_points2(Y0):\n",
    "        Z = Zf(w, mu, lastY)\n",
    "        return Z\n",
    "    return classifying_unknown_points2\n",
    "g = classifications2(w, mu)\n",
    "\n",
    "plot_progression(trainedY, testC)\n",
    "#plot_model(f, lastY, testC, I)\n",
    "#plot_separation(g, lastY, testC, I)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lowerBoundary_setTrueZ = [0.65, 0.75, 0.85, 0.95, 0.99]\n",
    "\n",
    "def checkResults(n=I):\n",
    "    testY, testC = get_data_spiral_2d(n)\n",
    "    trainedY = YK(W, b, testY)\n",
    "    lastY = trainedY[K,:,:]\n",
    "    trainedZ = Zf(w,mu,lastY)\n",
    "\n",
    "    J_new=Jf(trainedZ,testC)\n",
    "    numTrue=0\n",
    "    numJTrue = 0\n",
    "    print(\"J_new:\", J_new)\n",
    "    numTrue = sum(1 if testC[i][0] else 0 for i in range(n))\n",
    "    print(\"Antall true:\", numTrue)\n",
    "    print(\"Lower boundary \\t Antall true i følge J \\t\\t Success rate[%]\")\n",
    "    for lowerBound in lowerBoundary_setTrueZ:\n",
    "        numTrue_J = sum(1 if trainedZ[i][0] >=lowerBound else 0 for i in range(n))\n",
    "        success_rate = round(numTrue_J/numTrue*100, 5)\n",
    "        print(lowerBound, numTrue_J, success_rate, sep=\"\\t\\t\\t\")\n",
    "    \n",
    "\n",
    "lastY = trainedY[K,:,:]\n",
    "trainedZ = Zf(w,mu,lastY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkResults()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#INITIALISING LIST, PART 2\n",
    "K = 10 #number of layers, arbitrary number\n",
    "Y0pic, C_pic = get_dataset(\"testing\")\n",
    "d = Y0pic.shape[0]\n",
    "I = Y0pic.shape[1]\n",
    "\n",
    "np.random.seed(0)\n",
    "W = np.random.randn(K,d,d)\n",
    "np.random.seed(0)\n",
    "b = np.random.randn(K,d,1)     #startverdier\n",
    "np.random.seed(0)\n",
    "mu = np.random.randn()\n",
    "np.random.seed(0)\n",
    "w = np.random.randn(d,1)\n",
    "h = 0.1\n",
    "\n",
    "Ulst = [W, b, w, mu]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#algorithm for pictures\n",
    "counter = 1\n",
    "\n",
    "#initializing list\n",
    "m = [0 for x in range(len(Ulst))]\n",
    "v = [0 for x in range(len(Ulst))]\n",
    "\n",
    "#for AdamAlg\n",
    "for i in range(1,101):   #Skal være 40001\n",
    "    Ulst, m, v = AdamAlg(Ulst, m, v, C_pic, Y0pic)\n",
    "    print(counter)\n",
    "    counter +=1\n",
    "\n",
    "saveU(\"MNIST\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "W, b, w, mu = Ulst\n",
    "testpic, testCp = get_dataset(\"testing\")\n",
    "I = testpic.shape[1]\n",
    "d = testpic.shape[0]\n",
    "trainedPic = YK(W, b, testpic)\n",
    "lastYPic = trainedPic[K,:,:]\n",
    "\n",
    "trainedZ = Zf(w, mu, lastYPic)\n",
    "\n",
    "#koden går mye raskere men J er jo alt for høy: 117.54204154098629"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lowerBoundary_setTrueZ = [0.65, 0.75, 0.85, 0.95, 0.99, 1.00]\n",
    "\n",
    "def checkResultsPic(n=I): \n",
    "    J_new=Jf(trainedZ,testCp)\n",
    "    numTrue_J = np.array([]) \n",
    "    print(\"J_new:\", J_new)\n",
    "    numTrue = sum(1 if testCp[i][0] else 0 for i in range(n))\n",
    "    print(\"Antall true:\", numTrue)\n",
    "    print(\"Lower boundary \\t Antall true i følge J \\t\\t Success rate[%]\")\n",
    "    for lowerBound in lowerBoundary_setTrueZ:\n",
    "        numTrue_J = sum(1 if trainedZ[i][0] >=lowerBound else 0 for i in range(n))\n",
    "        success_rate = round(numTrue_J/numTrue*100, 5)\n",
    "        print(lowerBound, numTrue_J, success_rate, sep=\"\\t\\t\\t\")\n",
    "\n",
    "checkResultsPic()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
